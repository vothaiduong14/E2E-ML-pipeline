{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/processed/train.csv')\n",
    "test_df = pd.read_csv('data/processed/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(['Response'], axis=1)\n",
    "y = train_df['Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.156856974690994"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ratio of majority class to minority class (for the unbalanced dataset)\n",
    "scale_pos_weight = round(len(train_df['Response']) / sum(train_df['Response']) - 1)\n",
    "scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {'max_depth': [3, 5, 6, 10, 12, 14], # Maximum depth of a tree\n",
    "              'learning_rate': [0.01, 0.1, 0.2, 0.3], # Step size shrinkage used in update to prevents overfitting\n",
    "              'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "              'colsample_bytree': np.arange(0.4, 1.0, 0.1), # Number of features supplied to a tree\n",
    "              'colsample_bylevel': np.arange(0.4, 1.0, 0.1),\n",
    "              'n_estimators': np.arange(100, 400, 100),\n",
    "              'gamma': np.arange(0, 0.3, 0.1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "estimator=XGBClassifier(objective='binary:logistic', \n",
    "                                                      tree_method=\"gpu_hist\", # Use GPU\n",
    "                                                      random_state=42,\n",
    "                                                      eval_metric='logloss',\n",
    "                                                      scale_pos_weight=scale_pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid = RandomizedSearchCV(estimator=estimator, param_distributions=xgb_params, n_iter=40, cv=5, verbose=3, random_state=42, n_jobs=-1, scoring = 'f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    }
   ],
   "source": [
    "xgb_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60db4a95f2f77f0e64254fe64ea89c0c25da9af74818a5649ffbcb32f1cf9c72"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
